# ğŸ“Š Monitor de Empleabilidad - Informe TÃ©cnico

**Curso:** Lenguaje de ProgramaciÃ³n 2  
**Fecha:** 30 Diciembre 2025

---

## ğŸ‘¥ Integrantes del Equipo

| Usuario GitHub | Estudiante | 
| :--- | :--- |
| **@huarcayaariasd-bit** | Huarcaya Arias, Danilo | 
| **@Joseflores23** | Flores Cueva, Jose Armando | 
| **@RichiTM28** | Terreros Mosquera, Wellington Ricardo | |

---

## 1. DescripciÃ³n y Objetivos ğŸ¯

Este proyecto es una herramienta de **Inteligencia de Negocios (BI)** enfocada en la empleabilidad. Su objetivo es extraer, procesar y visualizar en tiempo real las tecnologÃ­as mÃ¡s demandadas para desarrolladores de software, consolidando informaciÃ³n de mÃºltiples fuentes internacionales (LatinoamÃ©rica, Global Remoto y Startups de Silicon Valley).

---

## 2. PlaneaciÃ³n del DiseÃ±o y ExtracciÃ³n de Datos ğŸ› ï¸

### 2.1. SelecciÃ³n de Fuentes
Para garantizar una muestra representativa, se seleccionaron tres fuentes con arquitecturas diferentes:

* **GetOnBoard:** Fuente principal para LatinoamÃ©rica (TÃ©cnica: *Web Scraping*).
* **Remotive:** Fuente global para trabajo remoto (TÃ©cnica: *API REST*).
* **HackerNews:** Fuente de nicho para Startups de alto nivel (TÃ©cnica: *API PÃºblica*).

### 2.2. Estrategia de Filtrado: "LÃ³gica de ExclusiÃ³n"
Durante la fase de anÃ¡lisis, detectamos que filtrar estrictamente por la palabra "Junior" eliminaba el **90%** de las ofertas relevantes, ya que muchas empresas usan tÃ­tulos genÃ©ricos (ej: *"Python Developer"*).

> **SoluciÃ³n Implementada:**
> En lugar de buscar inclusivamente ("Junior"), aplicamos un algoritmo de exclusiÃ³n:
> *"Aceptar todas las ofertas disponibles, **EXCEPTO** aquellas que contengan explÃ­citamente tÃ©rminos de alta jerarquÃ­a (Senior, Lead, Principal, Manager, Architect)."*

### 2.3. EstructuraciÃ³n y NormalizaciÃ³n (Data Pipeline)
Se diseÃ±Ã³ un esquema unificado para combinar datos de HTML, JSON y Listas:

| Campo Unificado | Origen GetOnBoard | Origen Remotive | Origen HackerNews |
| :--- | :--- | :--- | :--- |
| **TÃ­tulo** | Tag `<a>.title` | Key `job['title']` | Key `story['title']` |
| **Empresa** | Texto inferido | Key `job['company_name']` | String "Startup (HN)" |
| **DescripciÃ³n** | TÃ­tulo crudo | TÃ­tulo + Tags | TÃ­tulo + Texto |
| **URL** | `href` relativo + Base | Key `job['url']` | URL construida con ID |

---

## 3. Arquitectura del Sistema âš™ï¸

El sistema sigue el patrÃ³n **ETL (Extract, Transform, Load)** integrado en una aplicaciÃ³n web interactiva.

```mermaid
graph LR
    A[Fuentes Externas] --> B(MÃ³dulos de ExtracciÃ³n);
    B --> C{NormalizaciÃ³n y Filtrado};
    C --> D[DataFrame Pandas];
    D --> E[(Archivo CSV Consolidado)];
    E --> F[VisualizaciÃ³n Streamlit];
```

### TecnologÃ­as Clave:
* **Streamlit:** Interfaz grÃ¡fica y reactividad (`st.rerun`).
* **BeautifulSoup4:** Parsing de HTML (GetOnBoard).
* **Urllib3:** Configurado para evasiÃ³n de bloqueos SSL (`verify=False`).
* **Pandas & Matplotlib:** ManipulaciÃ³n tabular y grÃ¡ficos estadÃ­sticos.

---

## 4. Estructura del Repositorio ğŸ“‚

```text
trabajo_final-lp2/
â”‚
â”œâ”€â”€ app.py                 # (Main) Orquestador de la aplicaciÃ³n web
â”œâ”€â”€ requirements.txt       # Dependencias del proyecto
â”œâ”€â”€ README.md              # DocumentaciÃ³n tÃ©cnica
â”‚
â”œâ”€â”€ modules/               # Capa de LÃ³gica de Negocio (Backend)
â”‚   â”œâ”€â”€ scraper_getonboard.py  # Web Scraping y manejo SSL
â”‚   â”œâ”€â”€ api_remotive.py        # Consumo API REST
â”‚   â””â”€â”€ api_hackernews.py      # Consumo API Iterativa
â”‚
â”œâ”€â”€ docs/                  # DocumentaciÃ³n adicional
â”‚   â””â”€â”€ diccionario_datos.md
â”‚
â””â”€â”€ data/                  # Capa de Persistencia
    â””â”€â”€ ofertas_consolidadas.csv
```

---

## 5. Evidencia del Trabajo en Equipo ğŸ¤

El desarrollo fue modular, permitiendo integraciÃ³n final en `app.py`.

### ğŸ‘¨â€ğŸ’» Danilo: IngenierÃ­a de Datos & Scraping
* ImplementaciÃ³n de `scraper_getonboard.py` (Manejo complejo de SSL).
* DefiniciÃ³n de `requirements.txt`.
* DocumentaciÃ³n tÃ©cnica en `docs/diccionario_datos.md`.

### ğŸ‘¨â€ğŸ’» Wellington: IntegraciÃ³n API & DocumentaciÃ³n
* ImplementaciÃ³n de `api_remotive.py` con filtrado de etiquetas.
* RedacciÃ³n del Informe TÃ©cnico (`README.md`).
* Control de calidad (QA) de la documentaciÃ³n.

### ğŸ‘¨â€ğŸ’» Jose: Desarrollo Frontend & API Secundaria
* Desarrollo del Dashboard en `app.py` (Streamlit).
* ImplementaciÃ³n de `api_hackernews.py`.
* LÃ³gica de visualizaciÃ³n y grÃ¡ficos.

---

## 6. Instrucciones de InstalaciÃ³n ğŸš€

1.  **Clonar repositorio** o descargar los archivos.
2.  **Instalar dependencias:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Ejecutar la aplicaciÃ³n:**
    ```bash
    streamlit run app.py
    ```

La aplicaciÃ³n abrirÃ¡ automÃ¡ticamente una pestaÃ±a en tu navegador predeterminado.






